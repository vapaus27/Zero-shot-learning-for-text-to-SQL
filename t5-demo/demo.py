from transformers import T5ForConditionalGeneration,T5Tokenizer, T5Config
import warnings
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

warnings.filterwarnings("ignore")

dataset_name = input("dataset name: ")
if dataset_name == "wiki":
    # wiki
    pretrained_path = "pretrained/t5-base-finetuned-wikiSQL"
elif dataset_name == "spider":
    #spider
    pretrained_path = "pretrained/t5-base-finetuned-spider"
else:
    raise NotImplementedError("No pretrained model finetuned on {}".format(dataset_name))

tokenizer = T5Tokenizer.from_pretrained(pretrained_path)
config = T5Config.from_pretrained(pretrained_path)
model = T5ForConditionalGeneration.from_pretrained(pretrained_path, config=config)

model.to(device)

def get_sql(query, columns=None):
    if columns is None or len(columns) == 0:
        input_text = "translate English to SQL:%s </s>" % query
    else:
        column_text = " <extra_id_1> ".join(columns)
        input_text = "translate English to SQL:{} <extra_id_0> {} </s>".format(query, column_text)
    features = tokenizer([input_text], return_tensors='pt')

    output = model.generate(input_ids=features['input_ids'].to(device),
                            attention_mask=features['attention_mask'].to(device))

    return tokenizer.decode(output[0], skip_special_tokens=True)


query = "How many models were finetuned using BERT as base model?"

while True:
    query = input("Please input question: \n")
    print("Please input column names in table header, separated by spaces")
    column = input("column name: ")
    columns = column.split()

    print("Question: ", query)
    print("Input {} table columns: ".format(len(columns)), columns)
    print("SQL generated by T5: ", get_sql(query, columns))

    go_on = input("input anything if you want to try again: ")
    if go_on == "":
        break